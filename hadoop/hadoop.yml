---

- name: common
  hosts: all
  sudo: yes
  roles:

    - role: common

      package_list:
        - emacs24-nox
        - curl
        - httpie
        - ssh
        - rsync
        - parted

      services_running:
        - ssh

- name: common
  hosts: hadoop_nodes
  sudo: yes
  roles:

    - role: common

      users:
        - name: hadoop
          shell: /bin/bash

      authorized_keys:
        - user: hadoop
          key: "{{ hadoop.key_public }}"
        - user: hadoop
          key: "{{ lookup('file', '~/.ssh/id_rsa.pub') }}"

      private_keys:
        - user: hadoop
          key: "{{ hadoop.key_private }}"

      directories:
        /hdfs:
          owner: hadoop
          group: hadoop

    - role: limits

      limits_conf_d_files:
        hadoop.conf:
          - domain: hadoop
            type: soft
            item: nofile
            value: 65535
          - domain: hadoop
            type: hard
            item: nofile
            value: 65535


- name: storage
  hosts: datanodes
  sudo: yes
  tasks:

    - name: storage | create partition label
      command: parted -s /dev/vdb mklabel gpt creates=/dev/vdb1
      tags: storage

    - name: storage | create partition
      command: parted -s /dev/vdb mkpart primary ext3 0% 100% creates=/dev/vdb1
      tags: storage

    - name: storage | format disks
      filesystem:
        dev: /dev/vdb1
        fstype: ext3
      tags: storage

    - name: storage | mount
      mount:
        name: /hdfs
        src: /dev/vdb1
        fstype: ext3
        state: "{{ item }}"
      with_items: [present, mounted]
      tags: storage

    - name: storage | fix permissions
      file:
        path: /hdfs
        owner: hadoop
        group: hadoop
        recurse: yes
      tags: storage


- name: zookeeper
  hosts: zookeeper
  sudo: yes
  roles:
    - role: zookeeper
      zookeeper_node_iface: ansible_eth1
      zookeeper_nodes: "{{ groups['zookeeper'] }}"

    - role: supervisord
      supervisord_programs:
        zookeeper:
          user: zookeeper
          command: /usr/share/zookeeper/bin/zkServer.sh start-foreground
          stdout_logfile: /var/log/zookeeper/stdout.log
          stderr_logfile: /var/log/zookeeper/stderr.log

- name: hadoop common
  hosts: hadoop_nodes
  sudo: yes
  roles:
    - role: java
    - role: supervisord
    

- name: hadoop common
  hosts: hadoop_nodes
  user: hadoop
  roles:
    - role: hadoop_install
    - role: hadoop_configure

      clear_configs:
        - core-site.xml
        - hdfs-site.xml
        - yarn-site.xml
        - mapred-site.xml

      core_site:
        fs.defaultFS:
          hdfs://futuresystems

        # fs.default.name:
        #   "hdfs://{{ hostvars[groups['namenodes'][0]].ansible_fqdn }}:9000"



      hdfs_site:
        dfs.namenode.name.dir: file:///hdfs/namenode
        dfs.replication: "{{ dfs_replication }}"

        # HA
        dfs.nameservices: futuresystems

        dfs.ha.namenodes.futuresystems: nn1,nn2
        dfs.namenode.rpc-address.futuresystems.nn1:
          "{{ hostvars[groups['namenodes'][0]].ansible_fqdn }}:8020"
        dfs.namenode.rpc-address.futuresystems.nn2:
          "{{ hostvars[groups['namenodes'][1]].ansible_fqdn }}:8020"

        dfs.namenode.http-address.futuresystems.nn1:
          "{{ hostvars[groups['namenodes'][0]].ansible_fqdn }}:50070"
        dfs.namenode.http-address.futuresystems.nn2:
          "{{ hostvars[groups['namenodes'][1]].ansible_fqdn }}:50070"

        dfs.namenode.shared.edits.dir:
          qjournal://master1.local:8485;master2.local:8485;master3.local:8485/futuresystems

        # dfs.journalnode.edits.dir:

        dfs.client.failover.proxy.provider.futuresystems:
          "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"

        dfs.ha.fencing.methods: sshfence
        dfs.ha.fencing.ssh.private-key-files:
          "{{ ansible_env.HOME }}/.ssh/id_rsa"
          

        dfs.ha.automatic-failover.enabled: "true"
        ha.zookeeper.quorum: "{{ zookeeper_hosts }}"
        

        # journalnodes
        dfs.journalnode.edits.dir:
          /hdfs/journalnode

        # datanodes
        dfs.datanode.data.dir: file:///hdfs/datanode


      mapred_site:
        mapred.job.tracker: master1.local:9001
        mapreduce.jobtracker.restart.recover: 'true'


- name: stop everything
  hosts: hadoop_nodes
  sudo: yes
  tasks:

    - name: stop supervisord
      shell: supervisorctl stop all || echo -n
      tags: stop

    - name: stop everything
      shell: killall -q -u hadoop java || echo -n
      tags: stop

## journal nodes need to be up for first_run to execute

- name: journal nodes
  hosts: journalnodes
  sudo: yes
  roles:

    - role: supervisord
      supervisord_programs:
        journalnode:
          command: bash -lc '. /home/hadoop/.bashrc; hdfs journalnode'
          user: hadoop
          stdout_logfile: /hdfs/journalnode-stdout.log
          stderr_logfile: /hdfs/journalnode-stderr.log



- name: init first name node
  hosts: namenodes[0]
  user: hadoop
  tasks:

    - name: namenode format
      command: hdfs namenode -format -force
      tags: first_run

    - name: initialize shared edits
      command: hdfs namenode -initializeSharedEdits -force
      tags: first_run

    - name: format zookeeper
      command: hdfs zkfc -formatZK -force
      tags: first_run

    - name: run for nn2
      command: hdfs namenode
      async: 100
      poll: 0
      tags: first_run


- name: init standby name node
  hosts: namenodes[1]
  user: hadoop
  tasks:
    - name: bootstrap standby node
      command: hdfs namenode -bootstrapStandby -force
      tags: first_run


- name: cleanup
  hosts: namenodes
  user: hadoop
  tasks:
    - name: stop NameNode tasks
      shell: for pid in $(jps | grep NameNode | cut -d' ' -f1); do kill $pid; done
      tags: first_run


- name: namenodes
  hosts: namenodes
  sudo: yes
  roles:
    - role: supervisord
      supervisord_programs:

        namenode:
          command: bash -lc '. /home/hadoop/.bashrc; hdfs namenode'
          user: hadoop
          stdout_logfile: /hdfs/namenode-stdout.log
          stderr_logfile: /hdfs/namenode-stderr.log

        zkfc:
          command: bash -lc '. /home/hadoop/.bashrc; hdfs zkfc'
          user: hadoop
          stdout_logfile: /hdfs/zkfc-stdout.log
          stderr_logfile: /hdfs/zkfc-stderr.log


- name: data nodes
  hosts: datanodes
  sudo: yes
  roles:
    - role: supervisord
      supervisord_programs:
        datanode:
          command: bash -lc '. /home/hadoop/.bashrc; hdfs datanode'
          user: hadoop
          stdout_logfile: /hdfs/datanode-stdout.log
          stderr_logfile: /hdfs/datanode-stderr.log


- name: history server
  hosts: historyserver
  sudo: yes
  roles:
    - role: supervisord
      supervisord_programs:
        historyserver:
          command: bash -lc '. ~hadoop/.bashrc; mapred historyserver'
          user: hadoop
          stdout_logfile: /hdfs/historyserver-stdout.log
          stderr_logfile: /hdfs/historyserver-stderr.log
